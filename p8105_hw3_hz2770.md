p8105\_hw3\_hz2770
================
Hao Zheng
2021/10/16

``` r
library(tidyverse)
```

    ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --

    ## v ggplot2 3.3.5     v purrr   0.3.4
    ## v tibble  3.1.4     v dplyr   1.0.7
    ## v tidyr   1.1.3     v stringr 1.4.0
    ## v readr   2.0.1     v forcats 0.5.1

    ## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

## Problem 1

First, load the “instacart” dataset.

``` r
library(p8105.datasets)
data("instacart")
```

Description of the dataset: The dataset “instacart” contains
`rnrows = 1,384,617`, `rncols = 15`. There are 4 character variables:
eval\_set, product\_name, aisle and department. All the other variables
are integer variables.

1.  Now, we want to see how many aisles are there in the dataset
    “instacart” and which aisle has the most orders.

``` r
sum_by_aisle = 
  instacart %>% 
  group_by(aisle) %>% 
  summarise(n_obs = n())

sum_by_aisle
```

    ## # A tibble: 134 x 2
    ##    aisle                  n_obs
    ##    <chr>                  <int>
    ##  1 air fresheners candles  1067
    ##  2 asian foods             7007
    ##  3 baby accessories         306
    ##  4 baby bath body care      328
    ##  5 baby food formula      13198
    ##  6 bakery desserts         1501
    ##  7 baking ingredients     13088
    ##  8 baking supplies decor   1094
    ##  9 beauty                   287
    ## 10 beers coolers           1839
    ## # ... with 124 more rows

``` r
sum_by_aisle %>% 
  filter(min_rank(desc(n_obs))< 2)
```

    ## # A tibble: 1 x 2
    ##   aisle             n_obs
    ##   <chr>             <int>
    ## 1 fresh vegetables 150609

There are 134 aisles in total, and the most items are ordered from the
aisle “fresh vegetables”, which is 1.50609^{5} in total.

2.  Then we try to show the number of items sold in each aisle with a
    number over 10000 via a scatter plot.

``` r
filter_sum_by_aisle = 
  sum_by_aisle %>% 
  filter(n_obs > 10000)

filter_sum_by_aisle
```

    ## # A tibble: 39 x 2
    ##    aisle                    n_obs
    ##    <chr>                    <int>
    ##  1 baby food formula        13198
    ##  2 baking ingredients       13088
    ##  3 bread                    23635
    ##  4 butter                   10575
    ##  5 candy chocolate          11453
    ##  6 canned jarred vegetables 12679
    ##  7 canned meals beans       11774
    ##  8 cereal                   16201
    ##  9 chips pretzels           31269
    ## 10 crackers                 19592
    ## # ... with 29 more rows

``` r
filter_sum_by_aisle %>%
  ggplot(aes(x = aisle, y = n_obs)) +
  geom_point() +
  labs(x = NULL, y = NULL) +
  scale_y_continuous(
    breaks = c(20000, 60000, 100000, 140000, 180000),
    labels = c("20000", "60000", "100000", "140000", "180000")
  ) +
  theme(axis.text.x = element_text(angle=90, hjust=1))
```

![](p8105_hw3_hz2770_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

Then we got that there are 39 aisles in total have more than 10000 items
sold, among which, “fresh fruits” and “fresh vegetables” have the most
sold.

3.  Create a table to show the top three items in aisle “baking
    ingredients”, “dog food care” and “packaged vegetables fruits”.

``` r
final_rank =
  instacart %>%
  filter(
    aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")
    ) %>% 
  group_by(aisle, product_name) %>% 
  summarise(n_obs = n()) %>% 
  filter(min_rank(desc(n_obs)) < 4) %>% 
  mutate(
    rank_in_aisle = min_rank(desc(n_obs))
    ) %>% 
  arrange(aisle, rank_in_aisle) %>% 
  select(aisle, rank_in_aisle, product_name, n_obs)
```

    ## `summarise()` has grouped output by 'aisle'. You can override using the `.groups` argument.

``` r
final_rank
```

    ## # A tibble: 9 x 4
    ## # Groups:   aisle [3]
    ##   aisle                      rank_in_aisle product_name                    n_obs
    ##   <chr>                              <int> <chr>                           <int>
    ## 1 baking ingredients                     1 Light Brown Sugar                 499
    ## 2 baking ingredients                     2 Pure Baking Soda                  387
    ## 3 baking ingredients                     3 Cane Sugar                        336
    ## 4 dog food care                          1 Snack Sticks Chicken & Rice Re~    30
    ## 5 dog food care                          2 Organix Chicken & Brown Rice R~    28
    ## 6 dog food care                          3 Small Dog Biscuits                 26
    ## 7 packaged vegetables fruits             1 Organic Baby Spinach             9784
    ## 8 packaged vegetables fruits             2 Organic Raspberries              5546
    ## 9 packaged vegetables fruits             3 Organic Blueberries              4966

4.  Now, show the mean hour of the day at which Pink Lady Apples and
    Coffee Ice Cream are ordered on each day of the week.

``` r
apple_and_coffee = 
  instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>%  
  summarise(
    mean_hour_of_day = mean(order_hour_of_day, na.rm = TRUE)
    ) %>% 
  pivot_wider( 
    names_from = "order_dow", 
    values_from = "mean_hour_of_day"
    ) 
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the `.groups` argument.

``` r
apple_and_coffee
```

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

## Problem 2

First, let us load the dataset brfss\_smart2010 from the P8105 datasets.

``` r
data("brfss_smart2010")

head(brfss_smart2010)
```

    ## # A tibble: 6 x 23
    ##    Year Locationabbr Locationdesc  Class  Topic  Question   Response Sample_Size
    ##   <int> <chr>        <chr>         <chr>  <chr>  <chr>      <chr>          <int>
    ## 1  2010 AL           AL - Jeffers~ Healt~ Overa~ How is yo~ Excelle~          94
    ## 2  2010 AL           AL - Jeffers~ Healt~ Overa~ How is yo~ Very go~         148
    ## 3  2010 AL           AL - Jeffers~ Healt~ Overa~ How is yo~ Good             208
    ## 4  2010 AL           AL - Jeffers~ Healt~ Overa~ How is yo~ Fair             107
    ## 5  2010 AL           AL - Jeffers~ Healt~ Overa~ How is yo~ Poor              45
    ## 6  2010 AL           AL - Jeffers~ Healt~ Fair ~ Health St~ Good or~         450
    ## # ... with 15 more variables: Data_value <dbl>, Confidence_limit_Low <dbl>,
    ## #   Confidence_limit_High <dbl>, Display_order <int>, Data_value_unit <chr>,
    ## #   Data_value_type <chr>, Data_Value_Footnote_Symbol <chr>,
    ## #   Data_Value_Footnote <chr>, DataSource <chr>, ClassId <chr>, TopicId <chr>,
    ## #   LocationID <chr>, QuestionID <chr>, RESPID <chr>, GeoLocation <chr>

<!-- First, do some data cleaning. -->
<!-- ```{r} -->
<!-- brfss_smart2010 = -->
<!--   janitor::clean_names(brfss_smart2010) %>% -->
<!--   filter(topic == "Overall Health", -->
<!--          response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% -->
<!--   mutate( -->
<!--     as.factor(response, levels = (display_oreder)) -->
<!--     ) -->
<!-- head(brfss_smart2010) -->
<!-- ``` -->
<!-- 1. Find the states that were observed at 7 or more locations in 2002. -->
<!-- ```{r} -->
<!-- df = -->
<!-- brfss_smart2010 %>% -->
<!--   filter(year == 2002) %>% -->
<!--   group_by(locationabbr) %>% -->
<!--   filter(count(distinct(locationdesc)) >= 7) -->
<!-- df -->
<!-- ``` -->

## Problem 3

``` r
getwd()
```

    ## [1] "C:/Users/hao/OneDrive/Documents/R file/P8105_R code/p8105_hw3_hz2770"

``` r
accel_data = read_csv("./data/accel_data.csv")
```

    ## Rows: 35 Columns: 1443

    ## -- Column specification --------------------------------------------------------
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...

    ## 
    ## i Use `spec()` to retrieve the full column specification for this data.
    ## i Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(accel_data)
```

    ## # A tibble: 6 x 1,443
    ##    week day_id day      activity.1 activity.2 activity.3 activity.4 activity.5
    ##   <dbl>  <dbl> <chr>         <dbl>      <dbl>      <dbl>      <dbl>      <dbl>
    ## 1     1      1 Friday         88.4       82.2       64.4       70.0       75.0
    ## 2     1      2 Monday          1          1          1          1          1  
    ## 3     1      3 Saturday        1          1          1          1          1  
    ## 4     1      4 Sunday          1          1          1          1          1  
    ## 5     1      5 Thursday       47.4       48.8       46.9       35.8       49.0
    ## 6     1      6 Tuesday        64.8       59.5       73.7       45.7       42.4
    ## # ... with 1,435 more variables: activity.6 <dbl>, activity.7 <dbl>,
    ## #   activity.8 <dbl>, activity.9 <dbl>, activity.10 <dbl>, activity.11 <dbl>,
    ## #   activity.12 <dbl>, activity.13 <dbl>, activity.14 <dbl>, activity.15 <dbl>,
    ## #   activity.16 <dbl>, activity.17 <dbl>, activity.18 <dbl>, activity.19 <dbl>,
    ## #   activity.20 <dbl>, activity.21 <dbl>, activity.22 <dbl>, activity.23 <dbl>,
    ## #   activity.24 <dbl>, activity.25 <dbl>, activity.26 <dbl>, activity.27 <dbl>,
    ## #   activity.28 <dbl>, activity.29 <dbl>, activity.30 <dbl>, ...

Now, we first clean the data as desired.

``` r
accel_data =
  accel_data %>% 
  janitor::clean_names() %>% 
  mutate(
    day_type = ifelse(day %in% c("Saturday", "Sunday"), "Weekend", "weekday")
  ) %>% 
  mutate_if(is.double, as.integer)
```

    ## Warning in FUN(X[[i]], ...): strings not representable in native encoding will
    ## be translated to UTF-8

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00C4>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00D6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00E4>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00F6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00DF>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00C6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00E6>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00D8>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00F8>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00C5>' to native encoding

    ## Warning in FUN(X[[i]], ...): unable to translate '<U+00E5>' to native encoding

``` r
accel_data
```

    ## # A tibble: 35 x 1,444
    ##     week day_id day       activity_1 activity_2 activity_3 activity_4 activity_5
    ##    <int>  <int> <chr>          <int>      <int>      <int>      <int>      <int>
    ##  1     1      1 Friday            88         82         64         70         75
    ##  2     1      2 Monday             1          1          1          1          1
    ##  3     1      3 Saturday           1          1          1          1          1
    ##  4     1      4 Sunday             1          1          1          1          1
    ##  5     1      5 Thursday          47         48         46         35         48
    ##  6     1      6 Tuesday           64         59         73         45         42
    ##  7     1      7 Wednesday         71        103         68         45         37
    ##  8     2      8 Friday           675        542       1010        779        509
    ##  9     2      9 Monday           291        335        393        335        263
    ## 10     2     10 Saturday          64         11          1          1          1
    ## # ... with 25 more rows, and 1,436 more variables: activity_6 <int>,
    ## #   activity_7 <int>, activity_8 <int>, activity_9 <int>, activity_10 <int>,
    ## #   activity_11 <int>, activity_12 <int>, activity_13 <int>, activity_14 <int>,
    ## #   activity_15 <int>, activity_16 <int>, activity_17 <int>, activity_18 <int>,
    ## #   activity_19 <int>, activity_20 <int>, activity_21 <int>, activity_22 <int>,
    ## #   activity_23 <int>, activity_24 <int>, activity_25 <int>, activity_26 <int>,
    ## #   activity_27 <int>, activity_28 <int>, activity_29 <int>, ...

The accel\_data contains 1444 variables and 35 observations. The
variables are week, day\_id, day, activity for 1440 minutes through the
day and day\_type. All the variables are integers apart from week,
day\_id, day and day\_type.
